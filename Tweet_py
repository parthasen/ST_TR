conda list
conda info --envs#find list of active enviroments
source activate PyAlgo#environment suitable
pip install tweepy#needed for twitter Python streaming
pip install --upgrade pip#needed for upgradation
python twitter_streaming.py > twitter_data.txt #to get result in txt file need to midify timely 
python twitter_manupulate.py #to get stream on terminal


tweepy
Twython

http://stocktwits.com/developers/contact
https://github.com/omab/python-social-auth/tree/master/social/backends
https://github.com/tweepy/tweepy
pip install tweepy
pip install csvkit
pip install Twython 
pip install simplejson

http://adilmoujahid.com/posts/2014/07/twitter-analytics/
http://www-scf.usc.edu/~aupadhya/Mining.pdf
http://arxiv.org/pdf/1506.01513.pdf
http://www.amazon.com/gp/product/B00SNNZPBU/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=B00SNNZPBU&linkCode=as2&tag=m09f58-20&linkId=XDNYKIWGBHUHHSFO
http://www.programmableweb.com/api/stocktwits
https://mktstk.wordpress.com/2015/03/10/mining-the-stocktwits-home-stream-part-ii/
http://psa.matiasaguirre.net/docs/backends/stocktwits.html
http://stocktwits.com/developers/docs/api#streams-symbol-docs
http://social-metrics.org/tutorial-list/
http://www.curiositybits.com/new-page-3/

http://nullege.com/codes/show/src@l@a@lassie-HEAD@lassie@filters@__init__.py/15/social.SOCIAL_MAPS
http://behavioralquant.com/exploring-social-media-analytics/
http://www.tradingwithpython.com/
http://tradingwithpython.blogspot.in/
https://github.com/kjam/python-web-scraping-tutorial
http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/
http://docs.python-guide.org/en/latest/scenarios/scrape/
http://marcobonzanini.com/2015/06/16/mining-twitter-data-with-python-and-js-part-7-geolocation-and-interactive-maps/
http://socialmedia-class.org/twittertutorial.html
https://github.com/sixohsix/twitter
https://wiki.python.org/moin/CheeseShopTutorial
https://pypi.python.org/pypi/twitter
https://github.com/bear/python-twitter
https://github.com/geduldig/TwitterAPI
https://pythonprogramming.net/twitter-api-streaming-tweets-python-tutorial/
http://static.unto.net/python-twitter/0.6/doc/twitter.html
https://code.activestate.com/pypm/import:twitter/
http://www.dototot.com/how-to-write-a-twitter-bot-with-python-and-tweepy/
https://dev.twitter.com/overview/api/twitter-libraries#python
https://github.com/ideoforms/python-twitter-examples
http://nodotcom.org/python-twitter-tutorial.html
http://mike.verdone.ca/twitter/
http://rickyrosario.com/blog/posting-to-twitter-from-python/
https://github.com/geduldig/TwitterAPI
https://wilsonericn.wordpress.com/2011/08/22/tweeting-in-python-the-easy-way/
http://stats.seandolinar.com/collecting-twitter-data-using-a-python-stream-listener/


***
"""
Use Twitter API to grab user information from list of organizations; 
export text file
Uses Twython module to access Twitter API
"""

import sys
import string
import simplejson
from twython import Twython

#WE WILL USE THE VARIABLES DAY, MONTH, AND YEAR FOR OUR OUTPUT FILE NAME
import datetime
now = datetime.datetime.now()
day=int(now.day)
month=int(now.month)
year=int(now.year)


#FOR OAUTH AUTHENTICATION -- NEEDED TO ACCESS THE TWITTER API
t = Twython(app_key='NzXtTd9phXedpBOmkr7cGQ',app_secret='rDzUxnriKRu29AYNaZTJy53i9nRthxA6OK133Qk4',oauth_token='91544161-wr7Wpg55JiJ1YIDdJtFOHwiq5j7fA6ZzmT5ejPCG5',oauth_token_secret='9eu94LBl2LYOieeAQoHoNVERHGSB1W6x76Kw4KrT4BY6o')
   
#REPLACE WITH YOUR LIST OF TWITTER USER IDS
ids = "4816,9715012,13023422, 13393052,  14226882,  14235041, 14292458, 14335586, 14730894,15029174, 15474846, 15634728, 15689319, 15782399, 15946841, 16116519, 16148677, 16223542,16315120, 16566133, 16686673, 16801671, 41900627, 42645839, 42731742, 44157002, 44988185,48073289, 48827616, 49702654, 50310311, 50361094,"

#ACCESS THE LOOKUP_USER METHOD OF THE TWITTER API -- GRAB INFO ON UP TO 100 IDS WITH EACH API CALL
#THE VARIABLE USERS IS A JSON FILE WITH DATA ON THE 32 TWITTER USERS LISTED ABOVE
users = t.lookup_user(user_id = ids)

#NAME OUR OUTPUT FILE - %i WILL BE REPLACED BY CURRENT MONTH, DAY, AND YEAR
outfn = "twitter_user_data_%i.%i.%i.txt" % (now.month, now.day, now.year)

#NAMES FOR HEADER ROW IN OUTPUT FILE
fields = "id screen_name name created_at url followers_count friends_count statuses_count \
    favourites_count listed_count \
    contributors_enabled description protected location lang expanded_url".split()

#INITIALIZE OUTPUT FILE AND WRITE HEADER ROW   
outfp = open(outfn, "w")
outfp.write(string.join(fields, "\t") + "\n")  # header

#THE VARIABLE 'USERS' CONTAINS INFORMATION OF THE 32 TWITTER USER IDS LISTED ABOVE
#THIS BLOCK WILL LOOP OVER EACH OF THESE IDS, CREATE VARIABLES, AND OUTPUT TO FILE
for entry in users:
    #CREATE EMPTY DICTIONARY
    r = {}
    for f in fields:
        r[f] = ""
    #ASSIGN VALUE OF 'ID' FIELD IN JSON TO 'ID' FIELD IN OUR DICTIONARY
    r['id'] = entry['id']
    #SAME WITH 'SCREEN_NAME' HERE, AND FOR REST OF THE VARIABLES
    r['screen_name'] = entry['screen_name']
    r['name'] = entry['name']
    r['created_at'] = entry['created_at']
    r['url'] = entry['url']
    r['followers_count'] = entry['followers_count']
    r['friends_count'] = entry['friends_count']
    r['statuses_count'] = entry['statuses_count']
    r['favourites_count'] = entry['favourites_count']
    r['listed_count'] = entry['listed_count']
    r['contributors_enabled'] = entry['contributors_enabled']
    r['description'] = entry['description']
    r['protected'] = entry['protected']
    r['location'] = entry['location']
    r['lang'] = entry['lang']
    #NOT EVERY ID WILL HAVE A 'URL' KEY, SO CHECK FOR ITS EXISTENCE WITH IF CLAUSE
    if 'url' in entry['entities']:
        r['expanded_url'] = entry['entities']['url']['urls'][0]['expanded_url']
    else:
        r['expanded_url'] = ''
    print r
    #CREATE EMPTY LIST
    lst = []
    #ADD DATA FOR EACH VARIABLE
    for f in fields:
        lst.append(unicode(r[f]).replace("\/", "/"))
    #WRITE ROW WITH DATA IN LIST
    outfp.write(string.join(lst, "\t").encode("utf-8") + "\n")

outfp.close()   

***
https://github.com/adilmoujahid/Twitter_Analytics/blob/master/analyze_tweets.py

##GET OLD TWITS
Not working: file saved at desktop>TWIT
https://github.com/Jefferson-Henrique/GetOldTweets-python
#ï»¿ lxml==3.5.0 pyquery==1.2.10
# -*- coding: utf-8 -*-
git clone https://github.com/Jefferson-Henrique/GetOldTweets-python
cd GetOldTweets-python
